import asyncio
import json
import re
from pathlib import Path

from tqdm import tqdm  # tqdm ì¶”ê°€

from configs.llm_manager import LLMManager


async def generate_distillation_data():
    # ë°ì´í„° ìƒì„±ìš©ì´ë¯€ë¡œ ë†’ì€ ì˜¨ë„ë¡œ ì„¤ì •
    llm = LLMManager.get_instance("gateway", temperature=0.8)

    category_info = {
        "ì „íˆ¬": "ë¬¼ë¦¬ì  ì¶©ëŒ, ìŠµê²©, ì‚´ê¸°, ë¬´ê¸° ì‚¬ìš©.",
        "ëŒ€í™”": "ìƒí˜¸ì‘ìš©, ì§ì ‘ í™”ë²•, ì–¸ì–´ì  ì†Œí†µ.",
        "í¥ì •": "ê°€ê²© í˜‘ìƒ, ë³´ìƒ ë°€ë‹¹, ê±°ë˜ ì œì•ˆ.",
        "íƒí—˜": "ê´€ì°°, ê±°ë¦¬ ìœ ì§€, ê¸°ì²™ íƒì§€, ì‚¬ë¬¼ ì¡°ì‚¬. ì•ˆì „í•˜ì§€ ì•Šì€ ì¥ì†Œì—ì„œ ë¯¸ì§€ì˜ NPCì™€ ì˜ˆìƒì¹˜ ëª»í•œ ì²« ë§Œë‚¨",
        "íšŒë³µ": "ì•„ì´í…œ ì¦‰ì‹œ ì‚¬ìš©, ìˆ˜ì¹˜ íšŒë³µ.",
        "íœ´ì‹": "ì•ˆì „í•œ ìˆ˜ë©´, ì •ì ì¸ íœ´ì‹.",
        "ì•Œ ìˆ˜ ì—†ìŒ": "ë°°ê²½ ë¬˜ì‚¬, ë…ë°±, ë‚ ì”¨.",
    }

    categories = list(category_info.keys())
    dataset = []

    distillation_prompt_template = """
    (ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ê³¼ ë™ì¼...)
    """

    total_categories = len(categories)
    total_attempts = 30
    total_steps = total_categories * total_attempts  # ì „ì²´ ì‘ì—… íšŸìˆ˜

    # 1. ë‹¨ì¼ ì§„í–‰ ë°”ë¡œ í†µí•© (position ì„¤ì • ì œê±°)
    pbar = tqdm(total=total_steps, desc="ğŸ“Š ë°ì´í„° ìƒì„± ì‹œì‘")

    for cat_idx, cat in enumerate(categories):
        for attempt in range(1, total_attempts + 1):
            try:
                # 2. ì§„í–‰ ë°”ì˜ ì„¤ëª…ì„ í˜„ì¬ ì¹´í…Œê³ ë¦¬ì™€ íšŸìˆ˜ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
                pbar.set_description(f"ğŸš€ {cat} ìƒì„± ì¤‘ ({attempt}/{total_attempts})")

                formatted_prompt = distillation_prompt_template.format(
                    category=cat, definition=category_info[cat], label_idx=cat_idx
                )

                response = await llm.ainvoke(formatted_prompt)
                content = response.content.strip()

                match = re.search(r"\[.*\]", content, re.DOTALL)
                if match:
                    items = json.loads(match.group())
                    dataset.extend(items)

                    # 3. ìš°ì¸¡ í¬ìŠ¤íŠ¸í”½ìŠ¤ì— ëˆ„ì  ê°œìˆ˜ í‘œì‹œ
                    pbar.set_postfix(total_collected=f"{len(dataset)}ê°œ")

                await asyncio.sleep(1)

            except Exception as e:
                # ì—ëŸ¬ ë°œìƒ ì‹œ ì§„í–‰ ë°”ë¥¼ ê¹¨ëœ¨ë¦¬ì§€ ì•Šê³  ìœ„ì— ë¡œê·¸ ì¶œë ¥
                tqdm.write(f"   - âŒ ì—ëŸ¬ [{cat} - {attempt}íšŒì°¨]: {str(e)[:50]}")

            finally:
                # ì„±ê³µí•˜ë“  ì‹¤íŒ¨í•˜ë“  ë°”ë¥¼ í•œ ì¹¸ ì „ì§„
                pbar.update(1)

    pbar.close()  # ì‘ì—… ì™„ë£Œ í›„ ë‹«ê¸°

    if dataset:
        await save_distillation_dataset(dataset)


async def save_distillation_dataset(dataset):
    # ì¤‘ë³µ ì œê±° (Text ê¸°ì¤€)
    unique_data = {d["text"]: d for d in dataset}.values()

    file_path = (
        Path(__file__).resolve().parents[2] / "train_data" / "distillation_data.json"
    )
    file_path.parent.mkdir(parents=True, exist_ok=True)

    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(list(unique_data), f, ensure_ascii=False, indent=2)

    tqdm.write(
        f"\nâœ¨ ì´ {len(unique_data)}ê°œì˜ ì§€ì‹ ì¦ë¥˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}"
    )


if __name__ == "__main__":
    asyncio.run(generate_distillation_data())
